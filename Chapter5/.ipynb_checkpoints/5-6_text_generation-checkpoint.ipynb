{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bim5DkEvmQ6M"
   },
   "source": [
    "### 5.6.7 문장 생성에 대한 전체 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MsdcSWxemDFQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import cupy as np   # GPU를 사용하면 주석 해제\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -- 각 설정값 --\n",
    "n_time = 20  # 시점의 수\n",
    "n_mid = 128  # 은닉층 뉴런 수\n",
    "\n",
    "eta = 0.01  # 학습률\n",
    "clip_const = 0.02  # 노름의 최댓값을 구하는 상수\n",
    "beta = 2  # 확률분포 폭(다음 시점에 올 문자를 예측할 때 사용)\n",
    "epoch = 50\n",
    "batch_size = 128\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def clip_grad(grads, max_norm):\n",
    "    norm = np.sqrt(np.sum(grads*grads))\n",
    "    r = max_norm / norm\n",
    "    if r < 1:\n",
    "        clipped_grads = grads * r\n",
    "    else:\n",
    "        clipped_grads = grads\n",
    "    return clipped_grads\n",
    "\n",
    "# -- 훈련용 텍스트  --\n",
    "with open(\"human_problem.txt\", mode=\"r\", encoding=\"utf-8-sig\") as f:  # 파일 읽어 들이기\n",
    "    text = f.read()\n",
    "print(\"문자 수:\", len(text))  # len()으로 문자열의 문자 수도 출력 가능\n",
    "\n",
    "# -- 문자와 인덱스 연결 --\n",
    "chars_list = sorted(list(set(text)))  # # set으로 문자 중복 제거\n",
    "n_chars = len(chars_list)\n",
    "print(\"문자 수(중복없음):\", n_chars)\n",
    "\n",
    "char_to_index = {}  # 문자가 키이고 인덱스가 값인 딕셔너리\n",
    "index_to_char = {}  # 인덱스가 키이고 문자가 값인 딕셔너리\n",
    "for i, char in enumerate(chars_list):\n",
    "    char_to_index[char] = i\n",
    "    index_to_char[i] = char\n",
    " \n",
    "# -- 시계열로 나열된 문자와 다음 차례 문자 --\n",
    "seq_chars = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - n_time):\n",
    "    seq_chars.append(text[i: i + n_time])\n",
    "    next_chars.append(text[i + n_time])\n",
    "\n",
    "#  -- 입력과 정답을 원핫 인코딩으로 표시 --\n",
    "input_data = np.zeros((len(seq_chars), n_time, n_chars), dtype=np.bool)\n",
    "correct_data = np.zeros((len(seq_chars), n_chars), dtype=np.bool)\n",
    "for i, chars in enumerate(seq_chars):\n",
    "    correct_data[i, char_to_index[next_chars[i]]] = 1  # 정답을 원핫 인코딩으로 표시\n",
    "    for j, char in enumerate(chars):\n",
    "        input_data[i, j, char_to_index[char]] = 1  # 입력을 원핫 인코딩으로 표시 \n",
    "\n",
    "# -- LSTM층-- \n",
    "class LSTMLayer:\n",
    "    def __init__(self, n_upper, n):\n",
    "        # 각 파라미터의 초깃값\n",
    "        self.w = np.random.randn(4, n_upper, n) / np.sqrt(n_upper)  \n",
    "        self.v = np.random.randn(4, n, n) / np.sqrt(n)\n",
    "        self.b = np.zeros((4, n))\n",
    "\n",
    "    def forward(self, x, y_prev, c_prev):  ## y_prev, c_prev: 이전 시점의 출력과 기억 셀\n",
    "        u = np.matmul(x, self.w) + np.matmul(y_prev, self.v) + self.b.reshape(4, 1, -1)\n",
    "\n",
    "        a0 = sigmoid(u[0])  # 망각 게이트\n",
    "        a1 = sigmoid(u[1])  # 입력 게이트\n",
    "        a2 = np.tanh(u[2])  # 새로운 기억\n",
    "        a3 = sigmoid(u[3])  # 출력 게이트\n",
    "        self.gates = np.stack((a0, a1, a2, a3))\n",
    "\n",
    "        self.c = a0*c_prev + a1*a2  # 기억 셀\n",
    "        self.y = a3 * np.tanh(self.c)  # 출력\n",
    "    \n",
    "    def backward(self, x, y, c, y_prev, c_prev, gates, grad_y, grad_c, ):   \n",
    "        a0, a1, a2, a3 = gates\n",
    "        tanh_c = np.tanh(c)\n",
    "        r = grad_c + (grad_y*a3) * (1-tanh_c**2)\n",
    "\n",
    "        # 각delta\n",
    "        delta_a0 = r * c_prev * a0 * (1-a0)\n",
    "        delta_a1 = r * a2 * a1 * (1-a1)\n",
    "        delta_a2 = r * a1 * (1 - a2**2)\n",
    "        delta_a3 = grad_y * tanh_c * a3 * (1 - a3)\n",
    "\n",
    "        deltas = np.stack((delta_a0, delta_a1, delta_a2, delta_a3))\n",
    "\n",
    "        # 각 파라미터 기울기\n",
    "        self.grad_w += np.matmul(x.T, deltas)\n",
    "        self.grad_v += np.matmul(y_prev.T, deltas)\n",
    "        self.grad_b += np.sum(deltas, axis=1)\n",
    "\n",
    "        # x 기울기\n",
    "        grad_x = np.matmul(deltas, self.w.transpose(0, 2, 1))\n",
    "        self.grad_x = np.sum(grad_x, axis=0)\n",
    "\n",
    "        # y_prev 기울기\n",
    "        grad_y_prev = np.matmul(deltas, self.v.transpose(0, 2, 1))\n",
    "        self.grad_y_prev = np.sum(grad_y_prev, axis=0)\n",
    "        \n",
    "        # c_prev 기울기\n",
    "        self.grad_c_prev = r * a0\n",
    "\n",
    "    def reset_sum_grad(self):\n",
    "        self.grad_w = np.zeros_like(self.w)\n",
    "        self.grad_v = np.zeros_like(self.v)\n",
    "        self.grad_b = np.zeros_like(self.b)\n",
    "\n",
    "    def update(self, eta):\n",
    "        self.w -= eta * self.grad_w\n",
    "        self.v -= eta * self.grad_v\n",
    "        self.b -= eta * self.grad_b\n",
    "\n",
    "    def clip_grads(self, clip_const):\n",
    "        self.grad_w = clip_grad(self.grad_w, clip_const*np.sqrt(self.grad_w.size))\n",
    "        self.grad_v = clip_grad(self.grad_v, clip_const*np.sqrt(self.grad_v.size))\n",
    "\n",
    "# -- 전결합 출력층 --\n",
    "class OutputLayer:\n",
    "    def __init__(self, n_upper, n):\n",
    "        self.w = np.random.randn(n_upper, n) / np.sqrt(n_upper)  # 자비에르 초기화 기반의 초깃값\n",
    "        self.b = np.zeros(n)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        u = np.dot(x, self.w) + self.b\n",
    "        self.y = np.exp(u)/np.sum(np.exp(u), axis=1).reshape(-1, 1)  # 소프트맥스 함수\n",
    "\n",
    "    def backward(self, t):\n",
    "        delta = self.y - t\n",
    "        \n",
    "        self.grad_w = np.dot(self.x.T, delta)\n",
    "        self.grad_b = np.sum(delta, axis=0)\n",
    "        self.grad_x = np.dot(delta, self.w.T) \n",
    "\n",
    "    def update(self, eta):\n",
    "        self.w -= eta * self.grad_w\n",
    "        self.b -= eta * self.grad_b\n",
    "\n",
    "# -- 각 층의 초기화 --\n",
    "lstm_layer = LSTMLayer(n_chars, n_mid)\n",
    "output_layer = OutputLayer(n_mid, n_chars)\n",
    "\n",
    "# -- 훈련 --\n",
    "def train(x_mb, t_mb):\n",
    "    # 순전파 LSTM층\n",
    "    y_rnn = np.zeros((len(x_mb), n_time+1, n_mid))\n",
    "    c_rnn = np.zeros((len(x_mb), n_time+1, n_mid))\n",
    "    gates_rnn = np.zeros((4, len(x_mb), n_time, n_mid))\n",
    "    y_prev = y_rnn[:, 0, :]\n",
    "    c_prev = c_rnn[:, 0, :]\n",
    "    for i in range(n_time):\n",
    "        x = x_mb[:, i, :]\n",
    "        lstm_layer.forward(x, y_prev, c_prev)\n",
    "\n",
    "        y = lstm_layer.y\n",
    "        y_rnn[:, i+1, :] = y\n",
    "        y_prev = y\n",
    "\n",
    "        c = lstm_layer.c\n",
    "        c_rnn[:, i+1, :] = c\n",
    "        c_prev = c\n",
    "\n",
    "        gates = lstm_layer.gates\n",
    "        gates_rnn[:, :, i, :] = gates\n",
    "\n",
    "    # 순전파 출력층\n",
    "    output_layer.forward(y)\n",
    "\n",
    "    # 역전파 출력층\n",
    "    output_layer.backward(t_mb)\n",
    "    grad_y = output_layer.grad_x\n",
    "    grad_c = np.zeros_like(lstm_layer.c)\n",
    "\n",
    "    # 역전파 LSTM층\n",
    "    lstm_layer.reset_sum_grad()\n",
    "    for i in reversed(range(n_time)):\n",
    "        x = x_mb[:, i, :]\n",
    "        y = y_rnn[:, i+1, :]\n",
    "        c = c_rnn[:, i+1, :]\n",
    "        y_prev = y_rnn[:, i, :]\n",
    "        c_prev = c_rnn[:, i, :]\n",
    "        gates = gates_rnn[:, :, i, :] \n",
    "\n",
    "        lstm_layer.backward(x, y, c, y_prev, c_prev, gates, grad_y, grad_c)\n",
    "        grad_y = lstm_layer.grad_y_prev\n",
    "        grad_c = lstm_layer.grad_c_prev\n",
    "\n",
    "    # 파라미터 갱신\n",
    "    lstm_layer.clip_grads(clip_const)\n",
    "    lstm_layer.update(eta)\n",
    "    output_layer.update(eta)\n",
    "\n",
    "# -- 예측 --\n",
    "def predict(x_mb):\n",
    "    # 순전파 LSTM층\n",
    "    y_prev = np.zeros((len(x_mb), n_mid))\n",
    "    c_prev = np.zeros((len(x_mb), n_mid))\n",
    "    for i in range(n_time):\n",
    "        x = x_mb[:, i, :]\n",
    "        lstm_layer.forward(x, y_prev, c_prev)\n",
    "        y = lstm_layer.y\n",
    "        y_prev = y\n",
    "        c = lstm_layer.c\n",
    "        c_prev = c\n",
    "\n",
    "    # 순전파 출력층\n",
    "    output_layer.forward(y)\n",
    "    return output_layer.y\n",
    "\n",
    "# -- 오차 계산 --\n",
    "def get_error(x, t):\n",
    "    limit = 1000\n",
    "    if len(x) > limit:   # 측정 샘플 수 최댓값 설정\n",
    "        index_random = np.arange(len(x))\n",
    "        np.random.shuffle(index_random)\n",
    "        x = x[index_random[:limit], :]\n",
    "        t = t[index_random[:limit], :]\n",
    "    y = predict(x)\n",
    "    return -np.sum(t*np.log(y+1e-7))/batch_size  # 교차 엔트로피 오차\n",
    "\n",
    "def create_text():\n",
    "    prev_text = text[0:n_time]  # 입력\n",
    "    created_text = prev_text  # 생성되는 텍스트\n",
    "    print(\"Seed:\", created_text)\n",
    "\n",
    "    for i in range(200):  # 200자 문장 생성\n",
    "       # 입력을 원핫 인코딩으로 표시\n",
    "        x = np.zeros((1, n_time, n_chars))\n",
    "        for j, char in enumerate(prev_text):\n",
    "            x[0, j, char_to_index[char]] = 1\n",
    "        \n",
    "        # # 다음 문자 예측\n",
    "        y = predict(x)\n",
    "        p = y[0] ** beta  # 확률분포 조정\n",
    "        p = p / np.sum(p)  # p의 합을 1로\n",
    "        next_index = np.random.choice(len(p), size=1, p=p)\n",
    "        next_char = index_to_char[int(next_index[0])]\n",
    "        created_text += next_char\n",
    "        prev_text = prev_text[1:] + next_char\n",
    "\n",
    "    print(created_text)\n",
    "    print()  # 개행\n",
    "\n",
    "error_record = []\n",
    "n_batch = len(input_data) // batch_size  # 1에포크당 배치 개\n",
    "for i in range(epoch):\n",
    "        \n",
    "    # -- 학습 -- \n",
    "    index_random = np.arange(len(input_data))\n",
    "    np.random.shuffle(index_random)  # 인덱스 임의 섞기\n",
    "    for j in range(n_batch):\n",
    "        \n",
    "        # 미니 배치 구성\n",
    "        mb_index = index_random[j*batch_size : (j+1)*batch_size]\n",
    "        x_mb = input_data[mb_index, :]\n",
    "        t_mb = correct_data[mb_index, :]\n",
    "        train(x_mb, t_mb)\n",
    "\n",
    "        # -- 경과 표시 -- \n",
    "        print(\"\\rEpoch: \"+str(i+1)+\"/\"+str(epoch)+\"  \"+str(j+1)+\"/\"+str(n_batch), end=\"\")\n",
    "\n",
    "    # -- 오차 계산 --\n",
    "    error = get_error(input_data, correct_data)\n",
    "    error_record.append(error)\n",
    "    print(\"  Error: \"+str(error))\n",
    "\n",
    "    # -- 경과 표시 -- \n",
    "    create_text()\n",
    "\n",
    "plt.plot(range(1, len(error_record)+1), error_record, label=\"error\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "5-6_text_generation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
