{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rd4WZkPywQ72"
   },
   "source": [
    "### 9.2.1 ドロップアウト "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_eybU_zcaYTB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import cupy as np   # GPU를 사용하면 주석 해제\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "\n",
    "# -- 각 설정값 --\n",
    "img_size = 8  # 이미지 높이와 폭\n",
    "n_noise = 16  # 노이즈 수\n",
    "eta = 0.001  # 학습률\n",
    "n_learn = 10001  # 학습 횟수\n",
    "interval = 1000  # 경과 표시 간격\n",
    "batch_size = 32\n",
    "\n",
    "# -- 훈련 데이터 --\n",
    "digits_data = datasets.load_digits()\n",
    "x_train = np.asarray(digits_data.data)\n",
    "x_train = x_train / 15*2-1  # 범위는 -1에서 1사이\n",
    "t_train = digits_data.target\n",
    "\n",
    "# -- 전결합층의 부모 클래스 --\n",
    "class BaseLayer:\n",
    "    def update(self, eta):\n",
    "        self.w -= eta * self.grad_w\n",
    "        self.b -= eta * self.grad_b\n",
    "\n",
    "# -- 은닉층 --\n",
    "class MiddleLayer(BaseLayer):\n",
    "    def __init__(self, n_upper, n):\n",
    "        self.w = np.random.randn(n_upper, n) * np.sqrt(2/n_upper)  # He 초깃값\n",
    "        self.b = np.zeros(n)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        self.u = np.dot(x, self.w) + self.b\n",
    "        self.y = np.where(self.u <= 0, 0, self.u) # ReLU\n",
    "    \n",
    "    def backward(self, grad_y):\n",
    "        delta = grad_y * np.where(self.u <= 0, 0, 1)\n",
    "\n",
    "        self.grad_w = np.dot(self.x.T, delta)\n",
    "        self.grad_b = np.sum(delta, axis=0)     \n",
    "        self.grad_x = np.dot(delta, self.w.T) \n",
    "\n",
    "# -- 생성자 출력층 --\n",
    "class GenOutLayer(BaseLayer):\n",
    "    def __init__(self, n_upper, n):\n",
    "        self.w = np.random.randn(n_upper, n) / np.sqrt(n_upper)  # 자비에르 초기화 기반의 초깃값\n",
    "        self.b = np.zeros(n)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        u = np.dot(x, self.w) + self.b\n",
    "        self.y = np.tanh(u)  # tanh\n",
    "\n",
    "    def backward(self, grad_y):\n",
    "        delta = grad_y * (1 - self.y**2)\n",
    "        \n",
    "        self.grad_w = np.dot(self.x.T, delta)\n",
    "        self.grad_b = np.sum(delta, axis=0)    \n",
    "        self.grad_x = np.dot(delta, self.w.T) \n",
    "\n",
    "# -- 식별차 출력층 --\n",
    "class DiscOutLayer(BaseLayer):\n",
    "    def __init__(self, n_upper, n):\n",
    "        self.w = np.random.randn(n_upper, n) / np.sqrt(n_upper)  # 자비에르 초기화 기반의 초깃값\n",
    "        self.b = np.zeros(n)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        u = np.dot(x, self.w) + self.b\n",
    "        self.y = 1/(1+np.exp(-u))  # 시그모이드 함수\n",
    "\n",
    "    def backward(self, t):\n",
    "        delta = self.y-t\n",
    "        \n",
    "        self.grad_w = np.dot(self.x.T, delta)\n",
    "        self.grad_b = np.sum(delta, axis=0)  \n",
    "        self.grad_x = np.dot(delta, self.w.T) \n",
    "\n",
    "# -- 드롭 아웃 층 --\n",
    "class DropoutLayer:\n",
    "    def __init__(self, dropout_ratio):\n",
    "        self.dropout_ratio = dropout_ratio  # # 뉴런을 제거할 확률\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.is_train:  # is_train: 학습일 때 True\n",
    "            rand = np.random.rand(*x.shape)  # 입력과 동일한 형태의 난수 행렬\n",
    "            self.dropout = np.where(rand > self.dropout_ratio, 1, 0)  # 1:유효 0: 무효(제거)\n",
    "            self.y = x * self.dropout  # 뉴런을 무작위로 제거\n",
    "        else:\n",
    "            self.y = (1-self.dropout_ratio)*x   # 테스트일 때는 출력값을 낮춤\n",
    "        \n",
    "    def backward(self, grad_y):\n",
    "        self.grad_x = grad_y * self.dropout  # 제거된 뉴런에서는 역전파하지 않는다\n",
    "\n",
    "    def update(self, eta):\n",
    "        pass\n",
    "\n",
    "# -- 각 층의 초기화 --\n",
    "gen_layers = [MiddleLayer(n_noise, 32),\n",
    "              DropoutLayer(0.2),\n",
    "              MiddleLayer(32, 64),\n",
    "              DropoutLayer(0.2),\n",
    "              GenOutLayer(64, img_size*img_size)]\n",
    "\n",
    "disc_layers = [MiddleLayer(img_size*img_size, 64),\n",
    "               MiddleLayer(64, 32),\n",
    "               DiscOutLayer(32, 1)]\n",
    "\n",
    "# -- 순전파 --\n",
    "def forward_propagation(x, layers, is_train):\n",
    "    for layer in layers:\n",
    "        layer.is_train = is_train\n",
    "        layer.forward(x)\n",
    "        x = layer.y\n",
    "    return x\n",
    "\n",
    "# -- 역전파 --\n",
    "def backpropagation(t, layers):\n",
    "    grad_y = t\n",
    "    for layer in reversed(layers):\n",
    "        layer.backward(grad_y)\n",
    "        grad_y = layer.grad_x\n",
    "    return grad_y\n",
    "\n",
    "# -- 파라미터 갱신 --\n",
    "def update_params(layers):\n",
    "    for layer in layers:\n",
    "        layer.update(eta)\n",
    "\n",
    "# -- 오차 계산 --\n",
    "def get_error(y, t):\n",
    "    eps = 1e-7\n",
    "    return -np.sum(t*np.log(y+eps) + (1-t)*np.log(1-y+eps)) / len(y)  # 두 값의 교차 엔트로피 오차를 반환\n",
    "\n",
    "# --  정확도 계산 --\n",
    "def get_accuracy(y, t):\n",
    "    correct = np.sum(np.where(y<0.5, 0, 1) == t)\n",
    "    return correct / len(y)\n",
    "\n",
    "# -- - 모델 훈련 - --\n",
    "def train_model(x, t, prop_layers, update_layers):\n",
    "    y = forward_propagation(x, prop_layers, True)\n",
    "    backpropagation(t, prop_layers)\n",
    "    update_params(update_layers)\n",
    "    return (get_error(y, t), get_accuracy(y, t))\n",
    "\n",
    "# -- - 이미지를 생성하고 나타냄  --\n",
    "def generate_images(i):\n",
    "   # 이미지 생성\n",
    "    n_rows = 16  # 행수\n",
    "    n_cols = 16  # 열수\n",
    "    noise = np.random.normal(0, 1, (n_rows*n_cols, n_noise))\n",
    "    g_imgs = forward_propagation(noise, gen_layers, False)\n",
    "    g_imgs = g_imgs/2 + 0.5  # 범위는 0~1\n",
    "\n",
    "    img_size_spaced = img_size + 2\n",
    "    matrix_image = np.zeros((img_size_spaced*n_rows, img_size_spaced*n_cols))  # 이미지 전체\n",
    "\n",
    "    # 생성된 이미지를 나열해 1장의 이미지로 만듦\n",
    "    for r in range(n_rows):\n",
    "        for c in range(n_cols):\n",
    "            g_img = g_imgs[r*n_cols + c].reshape(img_size, img_size)\n",
    "            top = r*img_size_spaced\n",
    "            left = c*img_size_spaced\n",
    "            matrix_image[top : top+img_size, left : left+img_size] = g_img\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(matrix_image.tolist(), cmap=\"Greys_r\")\n",
    "    plt.tick_params(labelbottom=False, labelleft=False, bottom=False, left=False)   # 축 눈금의 레이블과 선을 삭제\n",
    "    plt.show()\n",
    "\n",
    "# -- GAN학습 --\n",
    "batch_half = batch_size // 2\n",
    "error_record = np.zeros((n_learn, 2))\n",
    "acc_record = np.zeros((n_learn, 2))\n",
    "for i in range(n_learn):\n",
    "    \n",
    "   # 노이즈에서 이미지를 생성하여 식별자를 훈련시킴\n",
    "    noise = np.random.normal(0, 1, (batch_half, n_noise))\n",
    "    imgs_fake = forward_propagation(noise, gen_layers, False)   # 이미지 생성\n",
    "    t = np.zeros((batch_half, 1))   # 정답은 0\n",
    "    error, accuracy = train_model(imgs_fake, t, disc_layers, disc_layers)\n",
    "    error_record[i][0] = error\n",
    "    acc_record[i][0] = accuracy\n",
    "\n",
    "    # 실제 이미지를 사용하여 식별자를 훈련시킴\n",
    "    rand_ids = np.random.randint(len(x_train), size=batch_half)\n",
    "    imgs_real = x_train[rand_ids, :]\n",
    "    t = np.ones((batch_half, 1))  # 정답은 1\n",
    "    error, accuracy = train_model(imgs_real, t, disc_layers, disc_layers)\n",
    "    error_record[i][1] = error\n",
    "    acc_record[i][1] = accuracy\n",
    "\n",
    "     # 생성자와 식별자 모델을 결합해 생성자만 훈련시킴\n",
    "    noise = np.random.normal(0, 1, (batch_size, n_noise))\n",
    "    t = np.ones((batch_size, 1))  # 정답은 1\n",
    "    train_model(noise, t, gen_layers+disc_layers, gen_layers)  # Generatorのみ訓練\n",
    "\n",
    "    # 일정한 간격으로 오차와 생성된 이미지를 나타냄\n",
    "    if i % interval == 0:\n",
    "        print (\"n_learn:\", i)\n",
    "        print (\"Error_fake:\", error_record[i][0] , \"Acc_fake:\", acc_record[i][0])\n",
    "        print (\"Error_real:\", error_record[i][1] , \"Acc_real:\", acc_record[i][1])\n",
    "        generate_images(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uaez9s_GwZAS"
   },
   "source": [
    "### 9.2.4 バッチ正規化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5UPhJ4k1weig"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import cupy as np   # GPU를 사용하면 주석 해제\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "\n",
    "# -- 각 설정값 --\n",
    "img_size = 8 # 이미지의 높이와 폭\n",
    "n_noise = 16 # 노이즈 수\n",
    "eta = 0.001 # 학습률\n",
    "n_learn = 10001 # 학습 횟수\n",
    "interval = 1000 # 학습 결과 표시 간격\n",
    "batch_size = 32\n",
    "\n",
    "# -- 훈련 데이터 --\n",
    "digits_data = datasets.load_digits()\n",
    "x_train = np.asarray(digits_data.data)\n",
    "x_train = x_train / 15*2-1  # 범위는 -1~1\n",
    "t_train = digits_data.target\n",
    "\n",
    "# --  전결합층의 부모 클래스 --\n",
    "class BaseLayer:\n",
    "    def update(self, eta):\n",
    "        self.w -= eta * self.grad_w\n",
    "        self.b -= eta * self.grad_b\n",
    "\n",
    "# -- 은닉층 --\n",
    "class MiddleLayer(BaseLayer):\n",
    "    def __init__(self, n_upper, n):\n",
    "        self.w = np.random.randn(n_upper, n) * np.sqrt(2/n_upper)  # He 초깃값\n",
    "        self.b = np.zeros(n)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        self.u = np.dot(x, self.w) + self.b\n",
    "        self.y = np.where(self.u <= 0, 0, self.u) # ReLU\n",
    "    \n",
    "    def backward(self, grad_y):\n",
    "        delta = grad_y * np.where(self.u <= 0, 0, 1)\n",
    "\n",
    "        self.grad_w = np.dot(self.x.T, delta)\n",
    "        self.grad_b = np.sum(delta, axis=0)     \n",
    "        self.grad_x = np.dot(delta, self.w.T) \n",
    "\n",
    "# -- Generatorの出力層 --\n",
    "class GenOutLayer(BaseLayer):\n",
    "    def __init__(self, n_upper, n):\n",
    "        self.w = np.random.randn(n_upper, n) / np.sqrt(n_upper)  # Xavierの初期値\n",
    "        self.b = np.zeros(n)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        u = np.dot(x, self.w) + self.b\n",
    "        self.y = np.tanh(u)  # tanh\n",
    "\n",
    "    def backward(self, grad_y):\n",
    "        delta = grad_y * (1 - self.y**2)\n",
    "        \n",
    "        self.grad_w = np.dot(self.x.T, delta)\n",
    "        self.grad_b = np.sum(delta, axis=0)    \n",
    "        self.grad_x = np.dot(delta, self.w.T) \n",
    "\n",
    "# -- 생성자의 출력층 --\n",
    "class DiscOutLayer(BaseLayer):\n",
    "    def __init__(self, n_upper, n):\n",
    "        self.w = np.random.randn(n_upper, n) / np.sqrt(n_upper)  # 자비에르 초기화 기반의 초깃값\n",
    "        self.b = np.zeros(n)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        u = np.dot(x, self.w) + self.b\n",
    "        self.y = 1/(1+np.exp(-u))  # 시그모이드 함수\n",
    "\n",
    "    def backward(self, t):\n",
    "        delta = self.y-t\n",
    "        \n",
    "        self.grad_w = np.dot(self.x.T, delta)\n",
    "        self.grad_b = np.sum(delta, axis=0)  \n",
    "        self.grad_x = np.dot(delta, self.w.T) \n",
    "\n",
    "# -- 배치 정규화 층 --\n",
    "class BatchNormLayer:\n",
    "    def __init__(self, n, alpha):\n",
    "        self.gamma = np.ones(n)\n",
    "        self.beta = np.zeros(n)\n",
    "\n",
    "        self.alpha = alpha  # 이동평균에 이용하는 상수\n",
    "        self.mov_ave = np.zeros(n)   # 평균의 이동평균\n",
    "        self.move_var = np.ones(n)   # 분산의 이동평균\n",
    "            \n",
    "    def forward(self, x):\n",
    "        eps = 1e-7  # 아주 작은 값   \n",
    "        if self.is_train:\n",
    "            self.mu = np.average(x, axis=0)\n",
    "            self.x_bar = x - self.mu\n",
    "            self.var = np.mean(self.x_bar**2, axis=0)\n",
    "            self.s = np.sqrt(self.var+eps)\n",
    "            self.x_hat = self.x_bar / self.s\n",
    "            \n",
    "            self.mov_ave = self.alpha*self.mu + (1-self.alpha)*self.mov_ave\n",
    "            self.move_var = self.alpha*self.var + (1-self.alpha)*self.move_var\n",
    "        else:\n",
    "            self.x_hat = (x-self.mov_ave) / (np.sqrt(self.move_var+eps))\n",
    "            \n",
    "        self.y = self.gamma*self.x_hat + self.beta \n",
    "\n",
    "    def backward(self, grad_y):\n",
    "        h = len(grad_y)   # 배치 사이즈\n",
    "\n",
    "        self.grad_gamma = np.sum(self.x_hat*grad_y, axis=0)\n",
    "        self.grad_beta = np.sum(grad_y, axis=0)\n",
    "\n",
    "        grad_x_hat = self.gamma * grad_y\n",
    "        grad_var = -0.5 / (self.s**3) * np.sum(self.x_bar*grad_x_hat, axis=0)\n",
    "        grad_x_bar = grad_x_hat/self.s + 2*self.x_bar/h*grad_var\n",
    "        grad_mu = -np.sum(grad_x_bar, axis=0)\n",
    "        self.grad_x = grad_x_bar + grad_mu/h\n",
    "        \n",
    "    def update(self, eta):\n",
    "        self.gamma -= eta * self.grad_gamma\n",
    "        self.beta -= eta * self.grad_beta\n",
    "\n",
    "# -- 각 층의 초기화 --\n",
    "gen_layers = [MiddleLayer(n_noise, 32),\n",
    "              BatchNormLayer(32, 0.1),\n",
    "              MiddleLayer(32, 64),\n",
    "              BatchNormLayer(64, 0.1),\n",
    "              GenOutLayer(64, img_size*img_size)]\n",
    "\n",
    "disc_layers = [MiddleLayer(img_size*img_size, 64),\n",
    "               MiddleLayer(64, 32),\n",
    "               DiscOutLayer(32, 1)]\n",
    "\n",
    "# -- 순전파 --\n",
    "def forward_propagation(x, layers, is_train):\n",
    "    for layer in layers:\n",
    "        layer.is_train = is_train\n",
    "        layer.forward(x)\n",
    "        x = layer.y\n",
    "    return x\n",
    "\n",
    "# -- 역전파 --\n",
    "def backpropagation(t, layers):\n",
    "    grad_y = t\n",
    "    for layer in reversed(layers):\n",
    "        layer.backward(grad_y)\n",
    "        grad_y = layer.grad_x\n",
    "    return grad_y\n",
    "\n",
    "# -- 파라미터 갱신 --\n",
    "def update_params(layers):\n",
    "    for layer in layers:\n",
    "        layer.update(eta)\n",
    "\n",
    "# -- 오차 계산 --\n",
    "def get_error(y, t):\n",
    "    eps = 1e-7\n",
    "    return -np.sum(t*np.log(y+eps) + (1-t)*np.log(1-y+eps)) / len(y)   # 두 값의 교차 엔트로피 오차를 반환\n",
    "\n",
    "# -- - 정확도 계산 -- --\n",
    "def get_accuracy(y, t):\n",
    "    correct = np.sum(np.where(y<0.5, 0, 1) == t)\n",
    "    return correct / len(y)\n",
    "\n",
    "# -- 모델 훈련 ----\n",
    "def train_model(x, t, prop_layers, update_layers):\n",
    "    y = forward_propagation(x, prop_layers, True)\n",
    "    backpropagation(t, prop_layers)\n",
    "    update_params(update_layers)\n",
    "    return (get_error(y, t), get_accuracy(y, t))\n",
    "\n",
    "# -- 이미지를 생성하고 나타냄 --\n",
    "def generate_images(i):\n",
    "    # 이미지 생성\n",
    "    n_rows = 16  # 행수\n",
    "    n_cols = 16  # 열수\n",
    "    noise = np.random.normal(0, 1, (n_rows*n_cols, n_noise))\n",
    "    g_imgs = forward_propagation(noise, gen_layers, False)\n",
    "    g_imgs = g_imgs/2 + 0.5  #  범위는 0~1\n",
    "\n",
    "    img_size_spaced = img_size + 2\n",
    "    matrix_image = np.zeros((img_size_spaced*n_rows, img_size_spaced*n_cols)) # 이미지 전체\n",
    "\n",
    "    # 생성된 이미지를 나열해 1장의 이미지로 만듦\n",
    "    for r in range(n_rows):\n",
    "        for c in range(n_cols):\n",
    "            g_img = g_imgs[r*n_cols + c].reshape(img_size, img_size)\n",
    "            top = r*img_size_spaced\n",
    "            left = c*img_size_spaced\n",
    "            matrix_image[top : top+img_size, left : left+img_size] = g_img\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(matrix_image.tolist(), cmap=\"Greys_r\")\n",
    "    plt.tick_params(labelbottom=False, labelleft=False, bottom=False, left=False)   # 축 눈금의 레이블과 선을 삭제\n",
    "    plt.show()\n",
    "\n",
    "# -- GAN 학습 --\n",
    "batch_half = batch_size // 2\n",
    "error_record = np.zeros((n_learn, 2))\n",
    "acc_record = np.zeros((n_learn, 2))\n",
    "for i in range(n_learn):\n",
    "    \n",
    "  # 노이즈에서 이미지를 생성하여 식별자를 훈련시킴\n",
    "    noise = np.random.normal(0, 1, (batch_half, n_noise))\n",
    "    imgs_fake = forward_propagation(noise, gen_layers, False)  # 이미지 생성\n",
    "    t = np.zeros((batch_half, 1))  # 정답은 0\n",
    "    error, accuracy = train_model(imgs_fake, t, disc_layers, disc_layers)\n",
    "    error_record[i][0] = error\n",
    "    acc_record[i][0] = accuracy\n",
    "\n",
    "   # 실제 이미지를 사용하여 식별자를 훈련시킴\n",
    "    rand_ids = np.random.randint(len(x_train), size=batch_half)\n",
    "    imgs_real = x_train[rand_ids, :]\n",
    "    t = np.ones((batch_half, 1))  # 정답은 1\n",
    "    error, accuracy = train_model(imgs_real, t, disc_layers, disc_layers)\n",
    "    error_record[i][1] = error\n",
    "    acc_record[i][1] = accuracy\n",
    "\n",
    "   # 생성자와 식별자 모델을 결합해 생성자만 훈련시킴\n",
    "    noise = np.random.normal(0, 1, (batch_size, n_noise))\n",
    "    t = np.ones((batch_size, 1))  # 정답은 1\n",
    "    train_model(noise, t, gen_layers+disc_layers, gen_layers) \n",
    "\n",
    "   # 일정한 간격으로 오차와 생성된 이미지를 나타냄\n",
    "    if i % interval == 0:\n",
    "        print (\"n_learn:\", i)\n",
    "        print (\"Error_fake:\", error_record[i][0] , \"Acc_fake:\", acc_record[i][0])\n",
    "        print (\"Error_real:\", error_record[i][1] , \"Acc_real:\", acc_record[i][1])\n",
    "        generate_images(i)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOM3QW0X50RKkQNcsMnQazu",
   "collapsed_sections": [],
   "name": "9-2_learning_techniques.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
